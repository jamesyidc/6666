#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ææ…Œæ¸…æ´—æŒ‡æ ‡æ•°æ®è¯»å–å™¨ V3
ä»Google Driveå…±äº«é“¾æ¥è¯»å–å®æ—¶æ•°æ®
"""

import asyncio
from playwright.async_api import async_playwright
from datetime import datetime
import pytz
import re

async def get_panic_wash_data_from_gdrive():
    """ä»Google Driveè¯»å–ææ…Œæ¸…æ´—æ•°æ®"""
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(beijing_tz)
    today = now.strftime('%Y-%m-%d')
    
    print(f"{'='*70}")
    print(f"ğŸ“¡ ä»Google Driveè·å–ææ…Œæ¸…æ´—æŒ‡æ ‡æ•°æ®")
    print(f"{'='*70}")
    print(f"â° å½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ ç›®æ ‡æ–‡ä»¶å¤¹: {today}")
    print(f"{'='*70}\n")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            viewport={'width': 1920, 'height': 1080}
        )
        page = await context.new_page()
        
        try:
            # 1. è®¿é—®æ ¹æ–‡ä»¶å¤¹
            url = "https://drive.google.com/drive/folders/1-IfqZxMV9VCSg3ct6XVMyFtAbuCV3huQ"
            print(f"1ï¸âƒ£  è®¿é—®Google Driveæ ¹æ–‡ä»¶å¤¹...")
            await page.goto(url, wait_until='networkidle', timeout=30000)
            await asyncio.sleep(3)
            
            # 2. æŸ¥æ‰¾ä»Šå¤©æ—¥æœŸçš„æ–‡ä»¶å¤¹
            print(f"2ï¸âƒ£  æŸ¥æ‰¾æ–‡ä»¶å¤¹: {today}...")
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨
            folder_selectors = [
                f'[data-tooltip*="{today}"]',
                f'div[data-tooltip="{today}"]',
                f'[aria-label*="{today}"]',
            ]
            
            folder_found = False
            for selector in folder_selectors:
                try:
                    elements = await page.locator(selector).all()
                    if elements:
                        print(f"   âœ… æ‰¾åˆ°æ–‡ä»¶å¤¹ (ä½¿ç”¨é€‰æ‹©å™¨: {selector})")
                        await elements[0].dblclick()
                        folder_found = True
                        break
                except:
                    continue
            
            if not folder_found:
                print(f"   âŒ æœªæ‰¾åˆ° {today} æ–‡ä»¶å¤¹")
                return None
            
            await asyncio.sleep(4)
            
            # 3. æŸ¥æ‰¾å¹¶æ‰“å¼€ ææ…Œæ¸…æ´—.txt
            print(f"3ï¸âƒ£  æŸ¥æ‰¾æ–‡ä»¶: ææ…Œæ¸…æ´—.txt...")
            
            file_selectors = [
                '[data-tooltip*="ææ…Œæ¸…æ´—.txt"]',
                '[aria-label*="ææ…Œæ¸…æ´—.txt"]',
                'div[data-tooltip="ææ…Œæ¸…æ´—.txt"]',
            ]
            
            file_found = False
            for selector in file_selectors:
                try:
                    elements = await page.locator(selector).all()
                    if elements:
                        print(f"   âœ… æ‰¾åˆ°æ–‡ä»¶ (ä½¿ç”¨é€‰æ‹©å™¨: {selector})")
                        await elements[0].click()
                        file_found = True
                        break
                except:
                    continue
            
            if not file_found:
                print(f"   âŒ æœªæ‰¾åˆ° ææ…Œæ¸…æ´—.txt æ–‡ä»¶")
                return None
            
            await asyncio.sleep(3)
            
            # 4. å°è¯•è¯»å–é¢„è§ˆå†…å®¹
            print(f"4ï¸âƒ£  è¯»å–æ–‡ä»¶å†…å®¹...")
            
            # æ–¹æ³•1: å°è¯•ä»é¢„è§ˆé¢æ¿è¯»å–
            preview_selectors = [
                '.preview-content',
                '.docs-text-content',
                'pre',
                '[role="textbox"]',
            ]
            
            for selector in preview_selectors:
                try:
                    element = await page.wait_for_selector(selector, timeout=5000)
                    if element:
                        text = await element.inner_text()
                        if text and len(text) > 10:
                            print(f"   âœ… ä»é¢„è§ˆé¢æ¿è·å–æ•°æ® (é•¿åº¦: {len(text)})")
                            parsed = parse_panic_wash_content(text)
                            if parsed:
                                return parsed
                except:
                    continue
            
            # æ–¹æ³•2: ä»é¡µé¢HTMLä¸­æå–
            print(f"   ğŸ”„ å°è¯•ä»é¡µé¢HTMLæå–...")
            content = await page.content()
            
            # æŸ¥æ‰¾åŒ…å«æ•°æ®çš„éƒ¨åˆ†
            if 'ææ…Œæ¸…æ´—æŒ‡æ ‡' in content or 'å¤šå¤´ä¸»å‡åŒºé—´' in content:
                parsed = parse_panic_wash_content(content)
                if parsed:
                    print(f"   âœ… ä»HTMLæå–æˆåŠŸ")
                    return parsed
            
            # æ–¹æ³•3: å°è¯•æ‰“å¼€æ–‡ä»¶åˆ°æ–°æ ‡ç­¾é¡µ
            print(f"   ğŸ”„ å°è¯•åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€æ–‡ä»¶...")
            try:
                # å³é”®ç‚¹å‡»æ–‡ä»¶
                await elements[0].click(button='right')
                await asyncio.sleep(1)
                
                # ç‚¹å‡»"åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€"
                open_button = await page.locator('text="åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€"').first
                if open_button:
                    await open_button.click()
                    await asyncio.sleep(3)
                    
                    # åˆ‡æ¢åˆ°æ–°æ ‡ç­¾é¡µ
                    pages = context.pages
                    if len(pages) > 1:
                        new_page = pages[-1]
                        await new_page.wait_for_load_state('networkidle')
                        content = await new_page.content()
                        parsed = parse_panic_wash_content(content)
                        if parsed:
                            print(f"   âœ… ä»æ–°æ ‡ç­¾é¡µæå–æˆåŠŸ")
                            return parsed
            except:
                pass
            
            print("   âŒ æ‰€æœ‰è¯»å–æ–¹æ³•å‡å¤±è´¥")
            return None
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
        finally:
            await browser.close()

def parse_panic_wash_content(content):
    """
    è§£æææ…Œæ¸…æ´—æ•°æ®å†…å®¹
    æ ¼å¼: 10.77-ç»¿|5-å¤šå¤´ä¸»å‡åŒºé—´-99305-2.26-92.18-2025-12-02 20:58:50
    """
    try:
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', content)
        
        # æŸ¥æ‰¾æ•°æ®è¡Œï¼ˆåŒ…å«æ•°å­—å’Œç«–çº¿åˆ†éš”ç¬¦çš„è¡Œï¼‰
        pattern = r'(\d+\.?\d*-[^|]+)\|(\d+)-([^-]+)-(\d+)-([\d.]+)-([\d.]+)-(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})'
        
        matches = re.findall(pattern, text)
        
        if matches:
            # å–ç¬¬ä¸€ä¸ªåŒ¹é…ï¼ˆæœ€æ–°çš„æ•°æ®ï¼‰
            match = matches[0]
            
            data = {
                'panic_indicator': match[0],  # 10.77-ç»¿
                'trend_rating': match[1],     # 5
                'market_zone': match[2],      # å¤šå¤´ä¸»å‡åŒºé—´
                'liquidation_24h_people': match[3],  # 99305
                'liquidation_24h_amount': match[4],  # 2.26
                'total_position': match[5],   # 92.18
                'update_time': match[6]       # 2025-12-02 20:58:50
            }
            
            print(f"\n{'='*70}")
            print(f"âœ… æˆåŠŸè§£ææ•°æ®:")
            print(f"{'='*70}")
            print(f"ğŸ“Š ææ…ŒæŒ‡æ ‡: {data['panic_indicator']}")
            print(f"ğŸ“ˆ è¶‹åŠ¿è¯„çº§: {data['trend_rating']}")
            print(f"ğŸ¯ å¸‚åœºåŒºé—´: {data['market_zone']}")
            print(f"ğŸ‘¥ 24hçˆ†ä»“äººæ•°: {data['liquidation_24h_people']}")
            print(f"ğŸ’¸ 24hçˆ†ä»“é‡‘é¢: {data['liquidation_24h_amount']}")
            print(f"ğŸ’° å…¨ç½‘æŒä»“é‡: {data['total_position']}äº¿")
            print(f"â° æ›´æ–°æ—¶é—´: {data['update_time']}")
            print(f"{'='*70}\n")
            
            return data
        
        # å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±è´¥ï¼Œå°è¯•æŒ‰è¡Œè§£æ
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if '|' in line and '-' in line and not line.startswith('ææ…Œæ¸…æ´—æŒ‡æ ‡'):
                # å°è¯•è§£æè¿™ä¸€è¡Œ
                parts = line.split('|')
                if len(parts) >= 2:
                    left = parts[0].strip()
                    right = parts[1].strip()
                    
                    # å³è¾¹éƒ¨åˆ†ç”¨ - åˆ†å‰²
                    right_parts = right.split('-')
                    if len(right_parts) >= 7:
                        data = {
                            'panic_indicator': left,
                            'trend_rating': right_parts[0],
                            'market_zone': right_parts[1],
                            'liquidation_24h_people': right_parts[2],
                            'liquidation_24h_amount': right_parts[3],
                            'total_position': right_parts[4],
                            'update_time': f"{right_parts[5]} {right_parts[6]}"
                        }
                        
                        print(f"\n{'='*70}")
                        print(f"âœ… æˆåŠŸè§£ææ•°æ® (æŒ‰è¡Œæ–¹å¼):")
                        print(f"{'='*70}")
                        for key, value in data.items():
                            print(f"   {key}: {value}")
                        print(f"{'='*70}\n")
                        
                        return data
        
        return None
        
    except Exception as e:
        print(f"âŒ è§£æé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == '__main__':
    # æµ‹è¯•æ•°æ®è¯»å–
    result = asyncio.run(get_panic_wash_data_from_gdrive())
    
    if result:
        print('\n' + '='*70)
        print('âœ… æ•°æ®è·å–æˆåŠŸï¼')
        print('='*70)
    else:
        print('\n' + '='*70)
        print('âŒ æ•°æ®è·å–å¤±è´¥')
        print('='*70)
